"""
LangGraph æ™ºèƒ½Agentå·¥å…·è°ƒç”¨ç³»ç»Ÿ
=====================================

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„LangGraphå·¥ä½œæµç¤ºä¾‹ï¼Œå®ç°äº†æ™ºèƒ½Agentçš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼š

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ğŸš€ start_node: æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼ŒLLMè¿›è¡Œæ™ºèƒ½å†³ç­–
2. ğŸ¤” isUseTool: åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·è¿˜æ˜¯ç›´æ¥å›ç­”
3. ğŸ”§ tool_node: æ‰§è¡Œå…·ä½“çš„å·¥å…·è°ƒç”¨ï¼ˆå¦‚ç½‘ç»œæœç´¢ï¼‰
4. ğŸ¯ final_answer_node: ç”Ÿæˆæœ€ç»ˆå›ç­”å¹¶ç»“æŸæµç¨‹

å·¥ä½œæµç¨‹å›¾ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·è¾“å…¥    â”‚ -> â”‚ start_node   â”‚ -> â”‚ isUseToolåˆ¤æ–­   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ (LLMå†³ç­–)    â”‚    â”‚                 â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†‘                      â”‚
                          â”‚                      â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ tool_node    â”‚ <------ â”‚ éœ€è¦å·¥å…·ï¼Ÿ  â”‚
                   â”‚ (æ‰§è¡Œå·¥å…·)   â”‚         â”‚             â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚ final_answer    â”‚
                                            â”‚ (æœ€ç»ˆå›ç­”)      â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   END   â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æŠ€æœ¯ç‰¹ç‚¹ï¼š
- ğŸ”„ æ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨å¾ªç¯
- ğŸ“ å®Œæ•´çš„çŠ¶æ€ç®¡ç†å’Œå†å²è®°å½•
- ğŸ›¡ï¸ å¥å£®çš„é”™è¯¯å¤„ç†æœºåˆ¶
- ğŸ” è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—å’Œè°ƒè¯•ä¿¡æ¯

ä½œè€…ï¼šAIåŠ©æ‰‹
æ—¥æœŸï¼š2024å¹´
ç‰ˆæœ¬ï¼šv1.0
"""

# ================================
# 1. å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
# ================================

import os
import dotenv
import requests
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool, render_text_description
from langchain_core.utils.json import parse_json_markdown
from langchain_openai import ChatOpenAI
from langgraph.constants import END

# ================================
# 2. ç¯å¢ƒé…ç½®å’ŒLLMåˆå§‹åŒ–
# ================================

# åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶(.env)
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•æœ‰ .env æ–‡ä»¶ï¼ŒåŒ…å« OPENAI_API_KEY=your_key_here
dotenv.load_dotenv()

# æ£€æŸ¥ API å¯†é’¥é…ç½®
# ä»ç¯å¢ƒå˜é‡ä¸­è·å–OpenAI APIå¯†é’¥
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    print("ğŸ“ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®: OPENAI_API_KEY=your_api_key_here")
    print("ğŸ’¡ æˆ–è€…åœ¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­è®¾ç½®è¯¥å€¼")
    exit(1)

# åˆ›å»ºå¤§è¯­è¨€æ¨¡å‹å®ä¾‹
# ä½¿ç”¨ SiliconFlow æä¾›çš„ API æ¥å£ï¼Œå®Œå…¨å…¼å®¹ OpenAI æ ¼å¼
llm = ChatOpenAI(
    api_key=api_key,                                    # APIå¯†é’¥
    base_url="https://api.siliconflow.cn/v1/",         # SiliconFlow APIåœ°å€
    model="Qwen/Qwen2.5-72B-Instruct",                 # é€šä¹‰åƒé—®å¤§æ¨¡å‹
    temperature=0.3                                     # æ§åˆ¶å›å¤çš„éšæœºæ€§(0-1)
)

# å­—ç¬¦ä¸²è¾“å‡ºè§£æå™¨ï¼ˆå¤‡ç”¨ï¼Œä¸»è¦ä½¿ç”¨JSONè§£æå™¨ï¼‰
output_parser = StrOutputParser()

# ================================
# 3. æç¤ºè¯æ¨¡æ¿è®¾è®¡
# ================================

# ä¸»è¦çš„æç¤ºè¯æ¨¡æ¿
# è¿™ä¸ªæ¨¡æ¿å®šä¹‰äº†Agentçš„è¡Œä¸ºæ¨¡å¼å’Œè¾“å‡ºæ ¼å¼
promptTemplate = """
å°½å¯èƒ½çš„å¸®åŠ©ç”¨æˆ·å›ç­”ä»»ä½•é—®é¢˜ã€‚
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®å¿™è§£å†³é—®é¢˜ï¼š
{tools}

ç”¨æˆ·é—®é¢˜: {input}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ä¸¤ç§JSONæ ¼å¼ä¹‹ä¸€å›å¤ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼š

é€‰é¡¹1ï¼šå¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·æœç´¢ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨æ­¤æ ¼å¼ï¼š
```json
{{
    "reason": "éœ€è¦æœç´¢çš„åŸå› ",
    "action": "searxng_search",
    "action_input": "æœç´¢å…³é”®è¯"
}}
```

é€‰é¡¹2ï¼šå¦‚æœå·²ç»çŸ¥é“ç­”æ¡ˆæˆ–ä¸éœ€è¦æœç´¢ï¼Œè¯·ä½¿ç”¨æ­¤æ ¼å¼ï¼š
```json
{{
    "action": "Final Answer",
    "answer": "ä½ çš„å›ç­”å†…å®¹"
}}
```

é‡è¦ï¼šåªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å…¶ä»–æ–‡å­—ã€‚
"""

# æ„å»ºå®Œæ•´çš„èŠå¤©æç¤ºè¯æ¨¡æ¿
# åŒ…å«ç³»ç»Ÿæ¶ˆæ¯ã€ç”¨æˆ·æ¶ˆæ¯å’Œå·¥å…·è°ƒç”¨å†å²
prompt = ChatPromptTemplate.from_messages([
    {
        "role": "system",
        "content": "ä½ æ˜¯éå¸¸å¼ºå¤§çš„åŠ©æ‰‹ï¼Œä½ å¯ä»¥ä½¿ç”¨å„ç§å·¥å…·æ¥å®Œæˆäººç±»äº¤ç»™çš„é—®é¢˜å’Œä»»åŠ¡ã€‚"
    },
    {
        "role": "user",
        "content": promptTemplate  # ä¸»è¦çš„æŒ‡ä»¤æ¨¡æ¿
    },
    # å·¥å…·è°ƒç”¨å†å²çš„å ä½ç¬¦ï¼Œoptional=Trueè¡¨ç¤ºå¯ä»¥ä¸ºç©º
    MessagesPlaceholder(variable_name="agent_scratchpad", optional=True)
])


# ================================
# 4. å·¥å…·å®šä¹‰ - ç½‘ç»œæœç´¢åŠŸèƒ½
# ================================

@tool
def searxng_search(query: str) -> list:
    """
    ä½¿ç”¨SearXNGæœç´¢å¼•æ“è¿›è¡Œç½‘ç»œæœç´¢

    å‚æ•°:
        query (str): æœç´¢å…³é”®è¯æˆ–é—®é¢˜

    è¿”å›:
        list: æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å«titleã€contentã€urlå­—æ®µ

    æ³¨æ„:
        - éœ€è¦æœ¬åœ°è¿è¡ŒSearXNGæœåŠ¡åœ¨6688ç«¯å£
        - ä½¿ç”¨Bingæœç´¢å¼•æ“
        - é™åˆ¶è¿”å›å‰3ä¸ªç»“æœ
    """
    # SearXNGæœåŠ¡çš„æœç´¢ç«¯ç‚¹URL
    SEARXNG_URL = "http://localhost:6688/search"  # æ­£ç¡®çš„æœç´¢ç«¯ç‚¹

    print(f"ğŸ” [å·¥å…·-searxng_search] å¼€å§‹æœç´¢: {query}")

    # æ„å»ºæœç´¢å‚æ•°
    params = {
        "q": query,                 # æœç´¢æŸ¥è¯¢
        "format": "json",           # è¿”å›JSONæ ¼å¼
        "engines": "bing",          # ä½¿ç”¨Bingæœç´¢å¼•æ“
        "language": "zh-CN"         # ä¸­æ–‡æœç´¢
    }

    try:
        print(f"ğŸŒ [å·¥å…·-searxng_search] è¯·æ±‚URL: {SEARXNG_URL}")
        print(f"ğŸ“‹ [å·¥å…·-searxng_search] è¯·æ±‚å‚æ•°: {params}")

        response = requests.get(SEARXNG_URL, params=params, timeout=10)
        print(f"ğŸ“¡ [å·¥å…·-searxng_search] å“åº”çŠ¶æ€ç : {response.status_code}")

        if response.status_code == 200:
            res = response.json()
            print(f"ğŸ“Š [å·¥å…·-searxng_search] åŸå§‹å“åº”: {res}")

            # æ£€æŸ¥å“åº”ç»“æ„
            if "results" not in res:
                print(f"âš ï¸  [å·¥å…·-searxng_search] å“åº”ä¸­æ²¡æœ‰ 'results' å­—æ®µ")
                return []

            if not res["results"]:
                print(f"âš ï¸  [å·¥å…·-searxng_search] æœç´¢ç»“æœä¸ºç©º")
                return []

            result = []
            for item in res["results"]:
                # æ·»åŠ å­—æ®µå­˜åœ¨æ€§æ£€æŸ¥
                title = item.get("title", "æ— æ ‡é¢˜")
                content = item.get("content", "æ— å†…å®¹æè¿°")
                url = item.get("url", "æ— é“¾æ¥")

                result.append({
                    "title": title,
                    "content": content,
                    "url": url
                })

            print(f"âœ… [å·¥å…·-searxng_search] å¤„ç†åçš„æœç´¢ç»“æœ: {result}")
            return result[:3]
        else:
            print(f"âŒ [å·¥å…·-searxng_search] HTTPé”™è¯¯: {response.status_code}")
            print(f"ğŸ“„ [å·¥å…·-searxng_search] å“åº”å†…å®¹: {response.text}")
            return []

    except requests.exceptions.ConnectionError:
        print(f"âŒ [å·¥å…·-searxng_search] è¿æ¥é”™è¯¯: æ— æ³•è¿æ¥åˆ° SearXNG æœåŠ¡")
        return []
    except requests.exceptions.Timeout:
        print(f"âŒ [å·¥å…·-searxng_search] è¶…æ—¶é”™è¯¯: è¯·æ±‚è¶…æ—¶")
        return []
    except Exception as e:
        print(f"âŒ [å·¥å…·-searxng_search] æœªçŸ¥é”™è¯¯: {e}")
        return []


tools = [searxng_search]
prompt = prompt.partial(
    tools=render_text_description(tools),
    tool_names=",".join([tool.name for tool in tools])
)
print(prompt)

def jsonParser(message):
    """å®‰å…¨çš„JSONè§£æå™¨ï¼Œå¸¦æœ‰é”™è¯¯å¤„ç†"""
    try:
        print(f"ğŸ” [JSONè§£æ] åŸå§‹LLMè¾“å‡º: {message.content}")

        # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
        if not message.content or message.content.strip() == "":
            print("âš ï¸  [JSONè§£æ] LLMè¿”å›ç©ºå†…å®¹")
            return {"action": "Final Answer", "answer": "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–ç›¸å…³ä¿¡æ¯ã€‚"}

        # å°è¯•è§£æJSON
        result = parse_json_markdown(message.content)
        print(f"âœ… [JSONè§£æ] è§£ææˆåŠŸ: {result}")
        return result

    except Exception as e:
        print(f"âŒ [JSONè§£æ] è§£æå¤±è´¥: {e}")
        print(f"ğŸ“„ [JSONè§£æ] åŸå§‹å†…å®¹: '{message.content}'")

        # è¿”å›ä¸€ä¸ªé»˜è®¤çš„JSONç»“æ„
        return {
            "action": "Final Answer",
            "answer": f"è§£æå“åº”æ—¶å‡ºç°é”™è¯¯ï¼ŒåŸå§‹å›å¤: {message.content}"
        }
# ================================
# LangGraph å·¥ä½œæµå®ç°
# ================================

from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, List
import operator

# å®šä¹‰çŠ¶æ€ç»“æ„
class AgentState(TypedDict):
    input: str                                          # ç”¨æˆ·è¾“å…¥
    agent_scratchpad: Annotated[List, operator.add]    # å·¥å…·è°ƒç”¨å†å²
    output: str                                         # æœ€ç»ˆè¾“å‡º
    llm_decision: dict                                  # LLMå†³ç­–ç»“æœ
    tool_result: str                                    # å·¥å…·æ‰§è¡Œç»“æœ

def start_node(state: AgentState):
    """
    èµ·å§‹èŠ‚ç‚¹ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œç”ŸæˆLLMå“åº”
    """
    print(f"ğŸš€ [start_node] å¤„ç†ç”¨æˆ·è¾“å…¥: {state['input']}")

    # æ„å»ºagent_scratchpadçš„æ¶ˆæ¯åˆ—è¡¨
    from langchain_core.messages import HumanMessage, AIMessage

    scratchpad_messages = []
    if state.get("agent_scratchpad"):
        for item in state["agent_scratchpad"]:
            # å°†å·¥å…·è°ƒç”¨å†å²è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
            scratchpad_messages.append(HumanMessage(content=f"å·¥å…·è°ƒç”¨è®°å½•: {item}"))

    print(f"ğŸ“‹ [start_node] å·¥å…·è°ƒç”¨å†å²: {len(scratchpad_messages)} æ¡è®°å½•")

    # è°ƒç”¨LLMé“¾
    result = chain.invoke({
        "input": state["input"],
        "agent_scratchpad": scratchpad_messages
    })

    print(f"ğŸ’­ [start_node] LLMå†³ç­–ç»“æœ: {result}")

    # å°†LLMçš„å†³ç­–ç»“æœå­˜å‚¨åˆ°çŠ¶æ€ä¸­
    return {
        "llm_decision": result,
        "agent_scratchpad": state.get("agent_scratchpad", [])
    }

def isUseTool(state: AgentState):
    """
    åˆ¤æ–­èŠ‚ç‚¹ï¼šå†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
    """
    llm_decision = state.get("llm_decision", {})
    action = llm_decision.get("action", "")

    print(f"ğŸ¤” [isUseTool] åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å·¥å…·...")
    print(f"ğŸ“‹ [isUseTool] å†³ç­–åŠ¨ä½œ: {action}")

    if action == "Final Answer":
        print("âœ… [isUseTool] å†³ç­–: ç›´æ¥å›å¤ç”¨æˆ·")
        return "final_answer"
    elif action in [tool.name for tool in tools]:
        print(f"ğŸ”§ [isUseTool] å†³ç­–: ä½¿ç”¨å·¥å…· '{action}'")
        return "use_tool"
    else:
        print(f"âš ï¸  [isUseTool] æœªçŸ¥åŠ¨ä½œ: {action}ï¼Œé»˜è®¤ç›´æ¥å›å¤")
        return "final_answer"

def tool_node(state: AgentState):
    """
    å·¥å…·èŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨
    """
    llm_decision = state.get("llm_decision", {})
    action = llm_decision.get("action", "")
    action_input = llm_decision.get("action_input", "")

    print(f"ğŸ”§ [tool_node] æ‰§è¡Œå·¥å…·: {action}")
    print(f"ğŸ“¥ [tool_node] å·¥å…·è¾“å…¥: {action_input}")

    # æŸ¥æ‰¾å¹¶æ‰§è¡Œå¯¹åº”çš„å·¥å…·
    tool_result = None
    for tool in tools:
        if tool.name == action:
            try:
                tool_result = tool.invoke(action_input)
                print(f"âœ… [tool_node] å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                print(f"ğŸ“¤ [tool_node] å·¥å…·è¾“å‡º: {tool_result}")
                break
            except Exception as e:
                print(f"âŒ [tool_node] å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                tool_result = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}"
                break

    if tool_result is None:
        print(f"âŒ [tool_node] æ‰¾ä¸åˆ°å·¥å…·: {action}")
        tool_result = f"æ‰¾ä¸åˆ°å·¥å…·: {action}"

    # å°†å·¥å…·è°ƒç”¨è®°å½•æ·»åŠ åˆ°scratchpad
    tool_record = f"ä½¿ç”¨å·¥å…· {action}({action_input}) -> {tool_result}"

    return {
        "agent_scratchpad": [tool_record],
        "tool_result": tool_result
    }

def final_answer_node(state: AgentState):
    """
    æœ€ç»ˆå›ç­”èŠ‚ç‚¹ï¼šç”Ÿæˆæœ€ç»ˆè¾“å‡º
    """
    llm_decision = state.get("llm_decision", {})

    if llm_decision.get("action") == "Final Answer":
        final_output = llm_decision.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æä¾›ç­”æ¡ˆã€‚")
    else:
        final_output = "å¤„ç†å®Œæˆï¼Œä½†æ²¡æœ‰æ‰¾åˆ°æœ€ç»ˆç­”æ¡ˆã€‚"

    print(f"ğŸ¯ [final_answer_node] ç”Ÿæˆæœ€ç»ˆå›ç­”: {final_output}")

    return {
        "output": final_output
    }

# ================================
# æ„å»º LangGraph å·¥ä½œæµ
# ================================

# åˆ›å»ºçŠ¶æ€å›¾
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("start_node", start_node)
workflow.add_node("tool_node", tool_node)
workflow.add_node("final_answer_node", final_answer_node)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("start_node")

# æ·»åŠ æ¡ä»¶è¾¹ï¼šä»start_nodeæ ¹æ®isUseToolçš„åˆ¤æ–­ç»“æœè·¯ç”±
workflow.add_conditional_edges(
    "start_node",
    isUseTool,
    {
        "use_tool": "tool_node",
        "final_answer": "final_answer_node"
    }
)

# æ·»åŠ è¾¹ï¼šå·¥å…·æ‰§è¡Œå®Œæˆåå›åˆ°start_nodeç»§ç»­å¤„ç†
workflow.add_edge("tool_node", "start_node")

# æ·»åŠ è¾¹ï¼šæœ€ç»ˆå›ç­”åç»“æŸ
workflow.add_edge("final_answer_node", END)

# ç¼–è¯‘å·¥ä½œæµ
app = workflow.compile()

# å®šä¹‰LLMå¤„ç†é“¾ï¼ˆåœ¨å·¥ä½œæµç¼–è¯‘åå®šä¹‰ï¼Œé¿å…å¾ªç¯å¼•ç”¨ï¼‰
chain = prompt | llm | jsonParser

# ================================
# æµ‹è¯•å·¥ä½œæµ
# ================================

print("=" * 80)
print("ğŸš€ å¼€å§‹æµ‹è¯• LangGraph å·¥å…·è°ƒç”¨å·¥ä½œæµ")
print("=" * 80)

# æµ‹è¯•ç”¨ä¾‹1ï¼šéœ€è¦æœç´¢çš„é—®é¢˜
test_input = {
    "input": "åˆ˜äº¦è²æœ€è¿‘æœ‰ä»€ä¹ˆæ´»åŠ¨?",
    "agent_scratchpad": [],
    "output": "",
    "llm_decision": {},
    "tool_result": ""
}

print(f"\nğŸ“ æµ‹è¯•è¾“å…¥: {test_input['input']}")
print("-" * 60)

try:
    # æ‰§è¡Œå·¥ä½œæµ
    for step in app.stream(test_input):
        print(f"\nğŸ“Š [æ‰§è¡Œæ­¥éª¤] {step}")
        print("-" * 40)

    # è·å–æœ€ç»ˆç»“æœ
    final_result = app.invoke(test_input)

    print("\n" + "=" * 80)
    print("ğŸ¯ æœ€ç»ˆç»“æœ:")
    print("=" * 80)
    print(f"ç”¨æˆ·é—®é¢˜: {final_result.get('input', '')}")
    print(f"æœ€ç»ˆå›ç­”: {final_result.get('output', '')}")
    print(f"å·¥å…·è°ƒç”¨å†å²: {final_result.get('agent_scratchpad', [])}")

except Exception as e:
    print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 80)
print("âœ… å·¥ä½œæµæµ‹è¯•å®Œæˆ")
print("=" * 80)
